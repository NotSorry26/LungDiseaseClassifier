{"cells":[{"cell_type":"markdown","source":["### Linking to the google drive to access any data or files"],"metadata":{"id":"jWSE1T-cQ_PY"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16552,"status":"ok","timestamp":1725040850179,"user":{"displayName":"Narendran Shankar","userId":"00932937848183882512"},"user_tz":-480},"id":"oCJ-IZPzgNUL","outputId":"f688f713-bfae-4bad-def0-c4913756b480"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["# Mount Google Drive to access files\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","# Add the custom module path to sys.path to allow for imports from that directory\n","import sys\n","sys.path.append('/content/drive/MyDrive/main/src/')"]},{"cell_type":"markdown","source":["### Importing the required libraries"],"metadata":{"id":"kQ9aCG16TrzX"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"_-xVdBCkgnNC"},"outputs":[],"source":["# Automatically reload modules when they change\n","%load_ext autoreload\n","%autoreload 2\n","\n","# Import custom modules\n","from model import initialise_model\n","from utils import set_requires_grad, save_model\n","from data import load_data\n","\n","# Import standard libraries\n","import os\n","import random\n","\n","# Import data processing and visualisation libraries\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import cv2\n","import seaborn as sns\n","import warnings\n","\n","# Import PyTorch and torchvision libraries\n","import torch\n","import torchvision\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.utils.data as td\n","import torchvision.transforms as T\n","from torchvision.io import read_image\n","from torchvision import datasets, models, transforms"]},{"cell_type":"markdown","source":["### Setting up the seed and figure size"],"metadata":{"id":"Qv8HCWNEXGsE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"256zZmAwhUUa"},"outputs":[],"source":["# Configure Matplotlib to automatically adjust the figure size when saving plots\n","plt.rcParams[\"savefig.bbox\"] = 'tight'\n","\n","# Set a fixed seed for reproducibility\n","seed = 26\n","random.seed(seed)  # Seed for random module\n","torch.manual_seed(seed)  # Seed for PyTorch\n","torch.backends.cudnn.deterministic = True  # Ensures reproducibility in cuDNN\n","if torch.cuda.is_available():\n","    torch.cuda.manual_seed_all(seed)  # Seed for all GPUs if CUDA is available\n","np.random.seed(seed)  # Seed for NumPy"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26779,"status":"ok","timestamp":1725040905510,"user":{"displayName":"Narendran Shankar","userId":"00932937848183882512"},"user_tz":-480},"id":"nDUuDcP7hZWK","outputId":"40a63e3b-9eb6-40d2-c64e-0cd58ef48b12"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-d919c48543a5>:17: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model = torch.load(model_path, map_location=device)\n"]}],"source":["# Initialise parameters for model and data\n","num_classes = 3\n","batch_size = 32\n","num_workers = 12\n","norm_arr = ([0.5159, 0.5159, 0.5159], [0.2554, 0.2554, 0.2554])\n","feature_extract = False\n","use_pretrained = None\n","input_size = 256\n","images_dir = \"/content/drive/MyDrive/data/covid_pneumonia\"\n","class_names = ['COVID', 'Normal', 'Pneumonia']\n","\n","# Load data\n","data_loaders = load_data(images_dir, batch_size=batch_size, input_size=input_size, norm_arr=norm_arr, num_workers=num_workers)\n","\n","# Function to load a model and send it to the device\n","def load_model(model_path, device):\n","    model = torch.load(model_path, map_location=device)\n","    model = model.to(device)\n","    return model\n","\n","# Load pretrained models\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model_paths = [\n","    '/content/drive/MyDrive/models/densenet121_50_model_weights.pth',\n","    '/content/drive/MyDrive/models/resnet34_50_model_weights.pth',\n","    '/content/drive/MyDrive/models/mobile_net_v3_large_50_model_weights.pth',\n","    '/content/drive/MyDrive/models/efficient_net_b1_50_model_weights.pth',\n","    '/content/drive/MyDrive/models/densenet121_tl_50_model_weights.pth'\n","]\n","\n","models = [load_model(path, device) for path in model_paths]"]},{"cell_type":"markdown","source":["### Setting up the Grad-CAM class"],"metadata":{"id":"CPAqXb70WsZW"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"EZ0VgNaXhrQw"},"outputs":[],"source":["# Grad-CAM class definition\n","class GradCAM:\n","    def __init__(self, model, target_layer):\n","        self.model = model.eval()  # Set the model to evaluation mode\n","        self.featuremaps = []\n","        self.gradients = []\n","\n","        # Register hooks to capture gradients and feature maps\n","        target_layer.register_forward_hook(self.save_featuremaps)\n","        target_layer.register_backward_hook(self.save_gradients)\n","\n","    def save_featuremaps(self, module, input, output):\n","        self.featuremaps.append(output)  # Save forward pass feature maps\n","\n","    def save_gradients(self, module, grad_input, grad_output):\n","        self.gradients.append(grad_output[0])  # Save backward pass gradients\n","\n","    def get_cam_weights(self, grads):\n","        return np.mean(grads, axis=(1, 2))  # Compute weights by averaging gradients\n","\n","    def __call__(self, image, label=None):\n","        preds = self.model(image)  # Forward pass\n","        self.model.zero_grad()  # Zero the gradients\n","\n","        if label is None:\n","            label = preds.argmax(dim=1).item()  # Get the label with the highest score\n","\n","        preds[:, label].backward()  # Backward pass for the specific label\n","\n","        # Get the gradients and feature maps\n","        featuremaps = self.featuremaps[-1].cpu().data.numpy()[0, :]\n","        gradients = self.gradients[-1].cpu().data.numpy()[0, :]\n","\n","        weights = self.get_cam_weights(gradients)  # Compute weights\n","        cam = np.zeros(featuremaps.shape[1:], dtype=np.float32)\n","\n","        # Combine the feature maps using the weights to create the CAM\n","        for i, w in enumerate(weights):\n","            cam += w * featuremaps[i]\n","\n","        cam = np.maximum(cam, 0)  # Apply ReLU\n","        cam = cv2.resize(cam, image.shape[-2:][::-1])  # Resize CAM to image size\n","        cam = cam - np.min(cam)  # Normalise CAM\n","        cam = cam / np.max(cam)\n","        return label, cam"]},{"cell_type":"markdown","source":["### Generating the Grad-CAM visualisations"],"metadata":{"id":"8qeuZ4mcWjmN"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1ITXlqZw9G96LTCxfGA03jQDDUL38mgae"},"executionInfo":{"elapsed":40901,"status":"ok","timestamp":1725040946385,"user":{"displayName":"Narendran Shankar","userId":"00932937848183882512"},"user_tz":-480},"id":"EgGc_4kQ25oD","outputId":"9ebbaa09-4497-4390-e25e-4342e8eb397d"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Utility function to deprocess the image for visualisation\n","def deprocess_image(image):\n","    image = image.cpu().numpy()\n","    image = np.squeeze(np.transpose(image[0], (1, 2, 0)))\n","\n","    image = image * np.array((0.2554, 0.2554, 0.2554)) + np.array((0.5159, 0.5159, 0.5159))\n","    image = image.clip(0, 1)\n","    return image\n","\n","# Function to apply a mask to the image for visualisation\n","def apply_mask(image, mask):\n","    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n","    heatmap = np.float32(heatmap) / 255\n","    cam = heatmap + np.float32(image)\n","    cam = cam / np.max(cam)\n","    return np.uint8(255 * cam)\n","\n","# Function to get one sample image from each class\n","def get_sample_images(data_loader, num_samples=2):\n","    \"\"\" Get two sample from each class: COVID, Normal, and Pneumonia \"\"\"\n","    samples = {class_name: [] for class_name in class_names}\n","    for images, labels in data_loader:\n","        for img, lbl in zip(images, labels):\n","            class_name = class_names[lbl]\n","            if len(samples[class_name]) < num_samples:\n","                samples[class_name].append((img, lbl))\n","        if all(len(samples[class_name]) >= num_samples for class_name in class_names):\n","            break\n","    return samples\n","\n","# Get one image from each class\n","sample_images = get_sample_images(data_loaders['test'], num_samples=2)\n","\n","# Suppress warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","# Visualise Grad-CAM for each model using sample images\n","for class_name in class_names:\n","    for img_idx in range(2):\n","      image, label = sample_images[class_name][img_idx]\n","      image1 = image.to(device)\n","      label1 = label.to(device)\n","\n","      image1 = image1.view(1, 3, 256, 256)  # Reshape image for model input\n","\n","      cams = []\n","\n","      # Target layers based on model architectures\n","      target_layers = [\n","          models[0].features[-1],        # DenseNet121\n","          models[1].layer4[-1],          # ResNet34\n","          models[2].features[-1],        # MobileNetV3\n","          models[3].features[-1],        # EfficientNet B1\n","          models[4].features[-1],        # DenseNet121 Transfer Learning\n","      ]\n","\n","      # Generate Grad-CAM for each model\n","      for model, target_layer in zip(models, target_layers):\n","          cam_obj = GradCAM(model=model, target_layer=target_layer)\n","          _, cam = cam_obj(image1, label1)\n","          cams.append(cam)\n","\n","      # Deprocess and apply masks\n","      image1 = deprocess_image(image1)\n","      masked_images = [apply_mask(image1, cam)[:, :, ::-1] for cam in cams]\n","\n","      # Plot original image and CAMs\n","      fig, axes = plt.subplots(1, len(models) + 1, figsize=(24, 6))\n","      plt.setp(axes, xticks=[], yticks=[])\n","\n","      axes[0].imshow(image1)\n","      axes[0].set_xlabel(f\"{class_name} (ORIGINAL)\")\n","\n","      for ax, img, model_name in zip(axes[1:], masked_images, ['DENSENET', 'RESNET', 'MOBILENET', 'EFFICIENTNET', 'DENSENET TL']):\n","          ax.imshow(img)\n","          ax.set_xlabel(model_name)\n","\n","      plt.subplots_adjust(wspace=0.00, hspace=0.00)\n","      plt.show()"]}],"metadata":{"accelerator":"TPU","colab":{"gpuType":"V28","provenance":[],"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}